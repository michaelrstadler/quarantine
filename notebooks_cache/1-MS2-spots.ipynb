{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-05-26\n",
    "\n",
    "Well, I seem to have lost several days of work. I don't know what happened with Jupyter, but it colossally fucked me. I guess before I close a notebook I need to aggressively copy it or something. I don't know.\n",
    "\n",
    "Anyway, I'll pick up where the last notebook left off and try to fill in what I had. One thing I certainly need to do is to update the MS2 connecting functions to use nuclear masks. I also need to generally check these functions because I likely don't remember all the changes I made. Plus comment them up.\n",
    "\n",
    "Tasks for the whole shebang:\n",
    "\n",
    "1. Load files.\n",
    "2. Segment nuclei in 3D stacks.\n",
    "3. Connect nuclear segmentation in 4D stacks.\n",
    "4. Segment (detect) MS2 spots in 3D stcks.\n",
    "5. Connect segmented MS2 spots in 4D.\n",
    "6. Integrate volumes around spots.\n",
    "\n",
    "1-4 are mostly done. Need to finish 5, can get to work on 6. I am going to try to follow Ciera's advice and just get to the finish line in the dirtiest way possible so I can start getting a handle on how to optimize. So, let's fix up connecting 4D spots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import public packages.\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as ndi \n",
    "# from skimage import filters, measure, segmentation, transform, exposure, img_as_ubyte, feature, morphology\n",
    "#from skimage import filters, io\n",
    "from functools import partial\n",
    "from importlib import reload\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "#InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import my packages.\n",
    "import sys\n",
    "sys.path.append('/Users/MStadler/Bioinformatics/Projects/Zelda/Quarantine_analysis/bin')\n",
    "from imagep import (read_tiff_folder, read_tiff_lattice, viewer, viewer, \n",
    "                    segment_embryo, labelmask_apply_morphology, zstack_normalize_mean,\n",
    "                   peak_local_max_nD, gradient_nD, labelmask_filter_objsize, filter_labelmask,\n",
    "                   object_circularity, stack_bgsub, segment_nuclei3D_5, lattice_segment_nuclei_5,\n",
    "                   dog_filter, imfill, segMS2_3dstack)\n",
    "import imagep as imp\n",
    "reload(imp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MStadler/opt/anaconda3/lib/python3.7/site-packages/skimage/external/tifffile/tifffile.py:2135: UserWarning: tags are not ordered by code\n",
      "  warnings.warn(\"tags are not ordered by code\")\n"
     ]
    }
   ],
   "source": [
    "# Load stack.\n",
    "stack = read_tiff_lattice(\n",
    "    '/Users/MStadler/Bioinformatics/Projects/Zelda/Quarantine_analysis/data/20171207_Zldeve_em5_mv2/',\n",
    "    span=(0,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgsub = stack_bgsub(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MStadler/Bioinformatics/Projects/Zelda/Quarantine_analysis/bin/imagep.py:322: RuntimeWarning: invalid value encountered in sqrt\n",
      "  gradient = np.sqrt(sumsq)\n",
      "/Users/MStadler/Bioinformatics/Projects/Zelda/Quarantine_analysis/bin/imagep.py:781: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  circularity = 4 * np.pi * area / (perimeter ** 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "mask = lattice_segment_nuclei_5(bgsub, seed_window=(70,50,50), circularity_min=0.1, size_max=7.5e5, size_min=0, erosion_length=5, dilation_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "\n",
    "def add_ms2_frame(spot_data, newframe_spotdata, nucmask, t, \n",
    "                  max_frame_gap=1, max_jump=10, scale_xy=1, scale_z=1):\n",
    "    \"\"\"Add spot detections for new frame to detection data for previous frames.\n",
    "    \n",
    "    Spots detected in new frame are connected to spots in previous frames\n",
    "    if they are within specified distance (max_jump) and contained within\n",
    "    the same nucleus. Spots can \"disappear\" for a number of frames defined\n",
    "    by max_frame_gap. Spots that cannot be connected to spots from prior\n",
    "    frames are initialized as new spots.\n",
    "    \n",
    "    Args:\n",
    "        spot_data: dict of ndarrays\n",
    "            Data containing tracking of spots detected in previous frames.\n",
    "            Dict entries are unique spot IDs (numeric 1...), rows of ndarray\n",
    "            are detections of the spot in a single frame. Column order is\n",
    "            0: frame no. (time), 1: nucleus ID, 2: z-coordinate, 3: x-\n",
    "            coordinate, 4: y-coordinate, 5: gaussian fit height, 6: gaussian\n",
    "            fit z-width, 7: gaussian fit x-width, 8: gaussian fit y-width.\n",
    "        newframe_spotdata: dict of ndarrays\n",
    "            Data for detected spots in frame to be added, returned from MS2\n",
    "            dot segmentation function. Dict keys are unique spot IDs (integers),\n",
    "            array entries are 0: z-coordinate, 1: x-coordinate, 2: y-coordinate, \n",
    "            3: gaussian fit height, 4: gaussian fit z-width, 5: gaussian fit \n",
    "            x-width, 6: gaussian fit y-width.\n",
    "        nucmask: ndarray\n",
    "            4D labelmask of dimensions [t,z,x,y] of segmented nuclei. 0 is \n",
    "            background (not a nucleus) and nuclei have integer labels.\n",
    "        t: int\n",
    "            Number of frame to be added.\n",
    "        max_frame_gap: int\n",
    "            Maximum number of frames from which spot can be absent and still\n",
    "            connected across the gap. Example: for a value of 1, a spot\n",
    "            detected in frame 6 and absent from frame 7 can be connected to\n",
    "            a spot in frame 8, but a spot in frame 5 cannot be connected to\n",
    "            frame 8 if it is absent in frames 6 and 7.\n",
    "        max_jump: numeric\n",
    "            Maximum 3D displacement between frames for two spots to be connected\n",
    "        scale_xy: numeric\n",
    "            Distance scale for xy direction (typically: nm per pixel)\n",
    "        scale_z: numeric\n",
    "            Distance scale for z direction (typically: nm per pixel)\n",
    "        \n",
    "    Returns:\n",
    "        spot_data: dict of ndarrays\n",
    "            Same structure as input spot_data with data from new frame added.\n",
    "    \"\"\"\n",
    "    def initialize_new_spot(new_spot_data, spot_data):\n",
    "        \"\"\"Initialize new spot with next numeric ID and entry in spot_data.\"\"\"\n",
    "        new_id = max(spot_data.keys()) + 1\n",
    "        spot_data[new_id] = np.expand_dims(new_spot_data, 0)\n",
    "\n",
    "    def sq_euc_distance(coords1, coords2, scale_z=1, scale_xy=1):\n",
    "        \"\"\"Find the squared euclidean distance between two points.\"\"\"\n",
    "        z2 = ((coords2[0] - coords1[0]) * scale_z) ** 2\n",
    "        x2 = ((coords2[1] - coords1[1]) * scale_xy) ** 2\n",
    "        y2 = ((coords2[2] - coords1[2]) * scale_xy) ** 2\n",
    "        sed = z2 + x2 + y2\n",
    "        return sed\n",
    "    \n",
    "    # Make a list of coordinates for all spots in a frame\n",
    "    def coord_list_t(spot_data, t):\n",
    "        \"\"\"Make a list of [z,x,y] coordinate tuples for all spots in a given\n",
    "        frame\"\"\"\n",
    "        coord_list = []\n",
    "        for spot_id in spot_data:\n",
    "            this_spot_data = spot_data[spot_id]\n",
    "            row = this_spot_data[this_spot_data[:,0] == t]\n",
    "            if (len(row) > 0):\n",
    "                row = list(row[0])\n",
    "                spot_coords = [spot_id] + row[2:5]\n",
    "                coord_list.append(spot_coords)\n",
    "        return coord_list\n",
    "            \n",
    "    \n",
    "    def find_nearest_spot(this_coord, coord_list, scale_z, scale_xy):\n",
    "        \"\"\"For a given point, find the closest spot in a coordinate list\n",
    "        and the distance between the points.\"\"\"\n",
    "        closest_sed = np.inf\n",
    "        closest_spot = 0\n",
    "        for test_data in coord_list:\n",
    "            test_spot_id = test_data[0]\n",
    "            test_coords = (test_data[1:4])\n",
    "            sed = sq_euc_distance(test_coords, this_coord, scale_z, scale_xy)\n",
    "            if (sed < closest_sed):\n",
    "                closest_sed = sed\n",
    "                closest_spot = test_spot_id\n",
    "                closest_spot_coords = test_coords\n",
    "        return closest_spot, np.sqrt(closest_sed), closest_spot_coords\n",
    "\n",
    "    def update_spot(this_spot_data, spot_data, scale_z, scale_xy, max_frame_gap, \n",
    "                    t):\n",
    "        \"\"\"Walk back one frame at a time within limit set by maximum gap, search \n",
    "        for a nearest spot that is within the maximum allowable jump, handle \n",
    "        duplicates, add connected points to spot_data.\"\"\"\n",
    "        this_spot_coords = (this_spot_data[2:5])\n",
    "        # Walk back one frame at a time.\n",
    "        for t_lag in range(1, max_frame_gap + 2):\n",
    "            if ((t - t_lag) >= 0):\n",
    "                # Get nearest spot in the current frame.\n",
    "                spot_coords_tlag = coord_list_t(spot_data, t - t_lag)\n",
    "                nearest_spot_id, dist, nearest_spot_coords = find_nearest_spot(this_spot_coords, spot_coords_tlag, scale_z, scale_xy)\n",
    "                # Check is spot is within max distance.\n",
    "                if (dist <= max_jump):\n",
    "                    this_spot_nucID = this_spot_data[1]\n",
    "                    nearest_spot_nucID = spot_data[nearest_spot_id][-1,1]\n",
    "                    # Check is spots are in the same nucleus.\n",
    "                    if (this_spot_nucID == nearest_spot_nucID):\n",
    "                        # Check if there's already a spot added for this time.\n",
    "                        existing = spot_data[nearest_spot_id][spot_data[nearest_spot_id][:,0] == t]\n",
    "                        # If there's no existing spot, add this spot to the end of the data for connected spot.\n",
    "                        if (len(existing) == 0):\n",
    "                            spot_data[nearest_spot_id] = np.append(spot_data[nearest_spot_id], [this_spot_data], axis=0)\n",
    "                            return\n",
    "                        # If there is an existing spot, if the current spot is closer to the previous-frame spot\n",
    "                        # than the existing entry, replace it. Otherwise, continue looking in previous frames (if\n",
    "                        # applicable) and eventually create new spot after for loop. I'm not sure this is the best\n",
    "                        # behavior--may consider dumping out of for loop and creating new spot rather than looking\n",
    "                        # to previous frames in this situation.\n",
    "                        else:\n",
    "                            existing_dist = np.sqrt(sq_euc_distance(nearest_spot_coords, existing[0,2:5], scale_z, scale_xy))\n",
    "                            # If the the current spot is closer than the existing spot, replace \n",
    "                            # existing and initialize it as a new spot.\n",
    "                            if (dist < existing_dist):\n",
    "                                row_index = np.where(spot_data[nearest_spot_id][:,0] == t)[0][0]\n",
    "                                superseded_spot_data = spot_data[nearest_spot_id][row_index]\n",
    "                                # Superseded spot from this frame gets bumped to be a new spot.\n",
    "                                initialize_new_spot(superseded_spot_data, spot_data)\n",
    "                                # Replace data for superseded spot with this spot's data.\n",
    "                                spot_data[nearest_spot_id][row_index] = this_spot_data\n",
    "                                return\n",
    "\n",
    "        # If no suitable spot was found in previous frames, make a new spot.\n",
    "        initialize_new_spot(this_spot_data, spot_data)\n",
    "        \n",
    "    \n",
    "    # Main\n",
    "    spot_data = spot_data.copy()\n",
    "    # Go through each spot in the new mask\n",
    "    for this_spot_id in newframe_spotdata:\n",
    "        spot_coords = tuple(np.append([t], newframe_spotdata[this_spot_id][0:3]).astype(int))\n",
    "        nuc_id = nucmask[spot_coords]\n",
    "        # Check if spot is in a nucleus.\n",
    "        if (nuc_id != 0):\n",
    "            # Add time and nuclear ID columns to spot data and call update to search \n",
    "            # for connected spots in previous frames.\n",
    "            this_spot_data = np.append([t, nuc_id], newframe_spotdata[this_spot_id])\n",
    "            update_spot(this_spot_data, spot_data, scale_z, scale_xy, max_frame_gap, t)\n",
    "    return spot_data   \n",
    "\n",
    "############################################################################\n",
    "def ms2_segment_stack(stack, channel, nucmask, seg_func=segMS2_3dstack, max_frame_gap=1, max_jump=10, \n",
    "                      scale_xy=1, scale_z=1, **kwargs):\n",
    "    \"\"\"Detect and segment MS2 spots from a 5D image stack.\n",
    "    \n",
    "    Mostly a wrapper for MS2 detection function and spot connector function\n",
    "    add_ms2_frame. Initializes spot_data structure using segmentation of \n",
    "    frame 0, then calls detector function and connector on each subsequent\n",
    "    frame. Is modular with respect to segmentation function: a new function\n",
    "    receives args from *kwargs. Connector is hard-coded as add_ms2_frame.\n",
    "    \n",
    "    Args:\n",
    "        stack: ndarray\n",
    "            5D image stack of dimensions [c,t,z,x,y] containing MS2 spots\n",
    "        channel: int\n",
    "            Channel containing MS2 spots\n",
    "        nucmask: ndarray\n",
    "            4D labelmask of dimensions [t,z,x,y] of segmented nuclei. 0 is \n",
    "            background (not a nucleus) and nuclei have integer labels.\n",
    "        seg_func: function\n",
    "            Function that performs segmentation of MS2 dots in a 3D stack\n",
    "        max_frame_gap: int\n",
    "            Maximum number of frames from which spot can be absent and still\n",
    "            connected across the gap. Example: for a value of 1, a spot\n",
    "            detected in frame 6 and absent from frame 7 can be connected to\n",
    "            a spot in frame 8, but a spot in frame 5 cannot be connected to\n",
    "            frame 8 if it is absent in frames 6 and 7.\n",
    "        max_jump: numeric\n",
    "            Maximum 3D displacement between frames for two spots to be connected\n",
    "        scale_xy: numeric\n",
    "            Distance scale for xy direction (typically: nm per pixel)\n",
    "        scale_z: numeric\n",
    "            Distance scale for z direction (typically: nm per pixel)\n",
    "        *kwargs: key-word arguments\n",
    "            Args supplied to segmentation function\n",
    "        \n",
    "    Returns:\n",
    "        spot_data: dict of ndarrays\n",
    "            Data containing tracking of spots detected. Dict entries are unique \n",
    "            spot IDs (numeric 1...), rows of ndarray are detections of the spot \n",
    "            in a single frame. Column order is 0: frame no. (time), 1: nucleus \n",
    "            ID, 2: z-coordinate, 3: x-coordinate, 4: y-coordinate, 5: gaussian \n",
    "            fit height, 6: gaussian fit z-width, 7: gaussian fit x-width, \n",
    "            8: gaussian fit y-width.   \n",
    "    \"\"\"\n",
    "    \n",
    "    def init_spot_data(data_f0, nucmask):\n",
    "        \"\"\"Initialize spot_data dict from data for first frame. Filters out spots \n",
    "        that are not in nuclei, relabels remaining spots 1...end, adds time 0 and\n",
    "        nucleus id to each data entry.\"\"\"\n",
    "        spot_id = 1\n",
    "        spot_data = {}\n",
    "        for n in data_f0:\n",
    "            spot_coords = tuple(np.append([0], data_f0[n][0:3]).astype(int))\n",
    "            nuc_id = nucmask[spot_coords]\n",
    "            if (nuc_id != 0):\n",
    "                spot_data[spot_id] = np.expand_dims(np.append([0, nuc_id], data_f0[n]), 0)\n",
    "                spot_id = spot_id + 1\n",
    "        return spot_data\n",
    "        \n",
    "    # Segment first frame and initialize spot data\n",
    "    nframes = stack[channel].shape[0]\n",
    "    spot_data_f0 = seg_func(stack[channel, 0], **kwargs)\n",
    "    spot_data = init_spot_data(spot_data_f0, nucmask)\n",
    "\n",
    "    # Segment and connect subsequent frames.\n",
    "    for t in range(1, nframes):\n",
    "        substack = stack[channel, t]\n",
    "        print(t)\n",
    "        frame_data = seg_func(substack, **kwargs)\n",
    "        spot_data = add_ms2_frame(spot_data, frame_data, nucmask, t, max_frame_gap=max_frame_gap,\n",
    "            max_jump=max_jump, scale_xy=scale_xy, scale_z=scale_z)\n",
    "    return spot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "reload(imp)\n",
    "spot_data=ms2_segment_stack(stack, 0, mask, imp.segMS2_3dstack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the morn:\n",
    "\n",
    "1. Comment and commit MS2 connector.\n",
    "2. Write volume integrator.\n",
    "\n",
    "In the afternoon:\n",
    "\n",
    "1. Run on several stacks.\n",
    "2. Write up notebook with analysis guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "def mesh_like(arr, n):\n",
    "    \"\"\"Make mesh grid for last n dimensions of an array\n",
    "    \n",
    "    Makes a meshgrid with the same shape as the last n dimensions of input\n",
    "    array-like object.\n",
    "    \n",
    "    Args:\n",
    "        arr: array-like\n",
    "            Array-like object that has a shape parameter\n",
    "        n: int\n",
    "            Number of dimensions, from the right, for which to make meshgrid.\n",
    "    \n",
    "    Returns:\n",
    "        meshes: list of ndarrays\n",
    "            Each element of list corresponds to ordered dimension of input,\n",
    "            ndarrays are corresponding meshgrids of same shape as arr.\n",
    "    \"\"\"\n",
    "    if (n > stack.ndim):\n",
    "        raise ValueError('n is larger than the dimension of the array')\n",
    "    # Make vectors of linear ranges for each dimension.\n",
    "    vectors = []\n",
    "    for i in reversed(range(1, n+1)):\n",
    "        a = np.arange(0, arr.shape[-i])\n",
    "        vectors.append(list(a))\n",
    "    # Make meshgrids from vectors.\n",
    "    meshes = np.meshgrid(*vectors, sparse=False, indexing='ij')\n",
    "    return meshes\n",
    "\n",
    "def add_volume_mean(spot_data, stack, channel, ij_rad, z_rad, ij_scale=1, z_scale=1):\n",
    "    \"\"\"Find mean volume within ellipsoid centered on spots, add to spot_info\n",
    "    \n",
    "    Args:\n",
    "        spot_data: dict of ndarrays\n",
    "            Data containing tracking of spots detected in previous frames.\n",
    "            Dict entries are unique spot IDs (numeric 1...), rows of ndarray\n",
    "            are detections of the spot in a single frame. Column order is\n",
    "            0: frame no. (time), 1: nucleus ID, 2: z-coordinate, 3: x-\n",
    "            coordinate, 4: y-coordinate, 5: gaussian fit height, 6: gaussian\n",
    "            fit z-width, 7: gaussian fit x-width, 8: gaussian fit y-width.\n",
    "        stack: ndarray\n",
    "            Image stack of dimensions [c,t,z,x,y]\n",
    "        channel: int\n",
    "            Channel containing MS2 spots\n",
    "        ij_rad: numeric\n",
    "            Radius in real units of ellipsoid in the ij (xy) dimension.\n",
    "        z_rad: numeric\n",
    "            Radius in real units of ellipsoid in the z dimension.\n",
    "        ij_scale: numeric\n",
    "            Scale factor for ij_rad (typically nm/pixel)\n",
    "        z_scale: numeric\n",
    "            Scale factor for z_rad (typically nm/pixel)\n",
    "    \n",
    "    Returns:\n",
    "        spot_data: dict of ndarrays\n",
    "            Input dictionary with mean ellipsoid pixel values appended as an \n",
    "            additional column (9) to all entries.\n",
    "    \"\"\"\n",
    "    def ellipsoid_mean(coords, stack, meshgrid, ij_rad, z_rad):\n",
    "        \"\"\"Define ellipsoid around point, return mean of pixel values in ellipsoid.\"\"\"\n",
    "        # Equation: (x-x0)^2 + (y-y0)^2 + a(z-z0)^2 = r^2\n",
    "        r = ij_rad # r is just more intuitive for me to think about...\n",
    "        a = (r ** 2) / (z_rad ** 2)\n",
    "        z0, i0, j0 = coords\n",
    "        valsgrid = np.sqrt((a * ((meshgrid[0] - z0) ** 2)) + ((meshgrid[1] - i0) ** 2) + ((meshgrid[2] - j0) ** 2))\n",
    "        pixels = stack[valsgrid <= r]\n",
    "        return pixels.mean()\n",
    "    \n",
    "    spot_data = spot_data.copy()\n",
    "    # Make meshgrid for stack.\n",
    "    meshgrid = mesh_like(stack, 3)\n",
    "    # Scale radii to pixels.\n",
    "    ij_rad_pix = ij_rad / ij_scale\n",
    "    z_rad_pix = z_rad / z_scale\n",
    "    # Update data for each spot at each time point combination by adding column\n",
    "    # with the sum of the pixel values within defined ellipses.\n",
    "    for spot_id in spot_data:\n",
    "        spot_array = spot_data[spot_id]\n",
    "        # Initialize new array with extra column.\n",
    "        new_array = np.ndarray((spot_array.shape[0], spot_array.shape[1] + 1))\n",
    "        for rownum in range(0, spot_array.shape[0]):\n",
    "            row = spot_array[rownum]\n",
    "            t = int(row[0])\n",
    "            coords = tuple(row[2:5].astype(int))\n",
    "            substack = stack[channel, t]\n",
    "            pix_mean = ellipsoid_mean(coords, substack, meshgrid, ij_rad_pix, z_rad_pix)\n",
    "            new_array[rownum] = np.append(row, [pix_mean])\n",
    "        spot_data[spot_id] = new_array\n",
    "    return spot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=add_volume_mean(spot_data, stack, 0, 10, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, just a day late! Volume integrator written. I now have the bare bones from loading the images to analyzing spots. I think the thing to do now is to bang on these functions on a few stacks. Take it out for a spin, refine, figure out how to go about optimizing parameters. Basically, I've done Ciera's get-through-it-shitty thing, and now it's time to dig in, start seeing if I can actually learn anything from this data.\n",
    "\n",
    "I will do so in a new notebook, though this one is quite short."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (image_analysis1)",
   "language": "python",
   "name": "image_analysis1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
